{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloelbrt/Research_internship_examples/blob/main/Rapport_MI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zsDWUk5cavn"
      },
      "source": [
        "# Unsupervised Learning Tutorial of Gianni Franchi\n",
        "PAN Herve - LEBRET Chlo√© - PAPADOPOULOS Robin \n",
        "\n",
        "Welcome to ML project!\n",
        "**In this notebook, you will**:\n",
        "- Learn what is SSL\n",
        "- Learn the difficulty with Overfitting\n",
        "- Learn to implement an Convolutional Neural Network.\n",
        "- Learn to train it when we don't have enough data\n",
        "\n",
        "If you have never used jupyter notebooks, nor Colab notebooks, [here](https://colab.research.google.com/notebooks/welcome.ipynb) is a short intro.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTJ7Zz6TAaJp"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from numpy import asarray\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import random\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "#import matplotlib.pyplot as plt\n",
        "#from modules import *\n",
        "#import torchvision.models as models_pytorch\n",
        "#import h5py\n",
        "#import torch.optim as optim\n",
        "#import augmentations\n",
        "from torch.nn.functional import kl_div, softmax, log_softmax\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from os.path import exists, join, split\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from PIL import Image, ImageFilter , ImageDraw\n",
        "import PIL\n",
        "import random\n",
        "#import madgrad \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#! pip install madgrad\n",
        "#! pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFCoFJzWApYo"
      },
      "outputs": [],
      "source": [
        "num_class = 10 #number of classes\n",
        "num_classes=num_class\n",
        "seed=111 #seed for the algorithm\n",
        "batch_size = 32\n",
        "num_train =100 # number of training image by classe\n",
        "cutout=16  # parameter for the cutout\n",
        "num_epochs=50\n",
        "#Validation set size\n",
        "valid_size = 200\n",
        "\n",
        "#An array with the different learning rates.\n",
        "\n",
        "lrarray=[0.001, 0.01, 0.1, 0.5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ux1VVt2AtcH"
      },
      "source": [
        "# First let us define a CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDbhFAHJAx97"
      },
      "outputs": [],
      "source": [
        "bn_momentum = 0.9\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
        "        init.constant_(m.bias, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "class WideBasic(nn.Module):\n",
        "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
        "        super(WideBasic, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes, momentum=bn_momentum)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, momentum=bn_momentum)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
        "        super(WideResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\n",
        "        n = int((depth - 4) / 6)\n",
        "        k = widen_factor\n",
        "\n",
        "        nStages = [16, 16*k, 32*k, 64*k]\n",
        "\n",
        "        self.conv1 = conv3x3(3, nStages[0])\n",
        "        self.layer1 = self._wide_layer(WideBasic, nStages[1], n, dropout_rate, stride=1)\n",
        "        self.layer2 = self._wide_layer(WideBasic, nStages[2], n, dropout_rate, stride=2)\n",
        "        self.layer3 = self._wide_layer(WideBasic, nStages[3], n, dropout_rate, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=bn_momentum)\n",
        "        self.linear = nn.Linear(nStages[3], num_classes)\n",
        "\n",
        "        # self.apply(conv_init)\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        # out = F.avg_pool2d(out, 8)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y7RH4rWA9c0"
      },
      "source": [
        "# now let us define a dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b7b754bf3d704c8ca49f3d94ffd0cb3c",
            "9950e6ede6c94882abdc259ef6e7e3fc",
            "2238772441414765a6c0d6b86337ef75",
            "e78b47908dae4bf9987f1d09cf94a089",
            "0e7987c8cf08428a98d2408c7732efa4",
            "0a9ed2f9b7064e83bc416e4409c30b74",
            "29376e5f1ace4d94ad9f5309c635a1e4",
            "ed0ca27c2a9342969d84fa318c4593eb",
            "302527af463746388f2d6f004df6fe44",
            "ef0a5ac2261349a58ea5a8ba73c2639a",
            "25467d38472b4631b0799f17dc4f0746"
          ]
        },
        "id": "JE1_MblIA5V7",
        "outputId": "5c7e8bab-a98c-4acd-c70d-499f5351f3f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7b754bf3d704c8ca49f3d94ffd0cb3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7b01e8055bc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#Dataset loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mCIFAR10_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0mCIFAR10_test_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files already downloaded and verified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgz_md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# check integrity of downloaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found or corrupted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: File not found or corrupted."
          ]
        }
      ],
      "source": [
        "class Dataset_sub_CIFAR(data.Dataset):\n",
        "\n",
        "    def __init__(self, data_feature, data_target,transform,phase='label'):\n",
        "        self.data_feature = data_feature\n",
        "        self.data_target = data_target\n",
        "        self.transform = transform\n",
        "        self.phase=phase\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_feature)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # load image as ndarray type (Height * Width * Channels)\n",
        "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
        "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
        "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
        "        if self.phase=='label':\n",
        "            data_feature = self.transform(Image.fromarray(np.uint8(self.data_feature[index])))\n",
        "            data_target =  self.data_target[index]\n",
        "            return data_feature, data_target\n",
        "\n",
        "        else:\n",
        "            data_feature = self.data_feature[index].float()\n",
        "            return data_feature\n",
        "\n",
        "\n",
        "class CutoutDefault(object):\n",
        "    \"\"\"\n",
        "    Reference : https://github.com/quark0/darts/blob/master/cnn/utils.py\n",
        "    \"\"\"\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if self.length <= 0:\n",
        "            return img\n",
        "        h, w = img.size(1), img.size(2)\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "\n",
        "        y1 = np.clip(y - self.length // 2, 0, h)\n",
        "        y2 = np.clip(y + self.length // 2, 0, h)\n",
        "        x1 = np.clip(x - self.length // 2, 0, w)\n",
        "        x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "        mask[y1: y2, x1: x2] = 0.\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img *= mask\n",
        "        return img\n",
        "\n",
        "    \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4, padding_mode = 'reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "    CutoutDefault(cutout),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "\n",
        "############################## CHOISIR entre les deux data augmentations\n",
        "res_size=224\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize([res_size, res_size]),\n",
        "    transforms.RandomCrop(224, padding=4, padding_mode = 'reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "    CutoutDefault(cutout),\n",
        "])\n",
        "\n",
        " \n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize([res_size, res_size]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "#Dataset loading\n",
        "CIFAR10_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=None, download=True)\n",
        "CIFAR10_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=None, download=True)\n",
        "\n",
        "#Dataset for Resnet Alexnet WideResnet etc..\n",
        "\n",
        "np.random.seed(seed=seed)\n",
        "permuation=np.random.permutation(len(CIFAR10_train_dataset.targets))\n",
        "\n",
        "Original_train_data_x = (CIFAR10_train_dataset.data)\n",
        "Original_train_data_y = np.array(CIFAR10_train_dataset.targets)\n",
        "Original_train_data_x = Original_train_data_x[permuation]\n",
        "Original_train_data_y = Original_train_data_y[permuation]\n",
        "\n",
        "Original_test_data_x = CIFAR10_test_dataset.data\n",
        "Original_test_data_y = np.array(CIFAR10_test_dataset.targets)\n",
        "\n",
        "#Selection of 250 labeled images for training and 2000 for validation\n",
        "incr_class = torch.zeros(num_class)\n",
        "train_idx_dico = {} #labeled images index dictionnary\n",
        "\n",
        "for i in range(num_class):\n",
        "    train_idx_dico[str(i)] = []\n",
        "\n",
        "valid_idx = np.zeros(num_class * valid_size, dtype=np.int32) #validation images indexes (2000)\n",
        "incr_t = 0\n",
        "incr_v = 0\n",
        "incrtotal = 0\n",
        "\n",
        "for idx in range(len(Original_train_data_y)):\n",
        "    class_y = Original_train_data_y[idx]\n",
        "    incrtotal += 1\n",
        "\n",
        "    train_idx_dico[str(class_y)].append(idx)\n",
        "    incr_class[class_y] += 1 #count the number of image per class\n",
        "    incr_t += 1\n",
        "\n",
        "\n",
        "train_idx = np.zeros(num_class * num_train, dtype=np.int32) #train labeled images indexes (1000)\n",
        "list_train_id = []\n",
        "list_unalabel_id = []\n",
        "valid_idx = []\n",
        "unlabel_idx_dico = {}\n",
        "for i in range(num_class):\n",
        "    unlabel_idx_dico[str(i)] = []\n",
        "for i in range(num_class):\n",
        "    list_train_id = list_train_id + train_idx_dico[str(i)][0:num_train]\n",
        "    valid_idx =valid_idx + train_idx_dico[str(i)][num_train:num_train+valid_size]\n",
        "    list_unalabel_id = list_unalabel_id + train_idx_dico[str(i)][num_train+valid_size::]\n",
        "    unlabel_idx_dico[str(i)] = train_idx_dico[str(i)][num_train::]\n",
        "\n",
        "#Get labeled and unlabeled data\n",
        "\n",
        "x_train = Original_train_data_x[[int(i) for i in list_train_id]]\n",
        "y_train = Original_train_data_y[[int(i) for i in list_train_id]]\n",
        "\n",
        "x_unlabeled = Original_train_data_x[[int(i) for i in list_unalabel_id]]\n",
        "y_unlabeled = Original_train_data_y[[int(i) for i in list_unalabel_id]]\n",
        "\n",
        "#Get validation set data\n",
        "x_valid = Original_train_data_x[[int(i) for i in valid_idx]]\n",
        "y_valid = Original_train_data_y[[int(i) for i in valid_idx]]\n",
        "\n",
        "# Printing the size of the training, validation and test sets\n",
        "print('Number of training examples: ' + str(x_train.shape[0]))\n",
        "print('Number of unlabeled examples: ' + str(x_unlabeled.shape[0]))\n",
        "print('Number of validation examples: ' + str(x_valid.shape[0]))\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "\n",
        "#Dataloader creation\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(Original_test_data_x, Original_test_data_y, transform=transform_test),\n",
        "    batch_size = batch_size,\n",
        "    shuffle=False, num_workers=2)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_train, y_train, transform=transform_train),\n",
        "    batch_size=batch_size,shuffle=True, num_workers=2) #num_workers = 2 ou 1\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_valid, y_valid, transform=transform_test),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW-PRa3bYJMS"
      },
      "outputs": [],
      "source": [
        "#We are going to use the scikit-learn library to use their SVC and Random forest model.\n",
        "#To train the model, we need to arrange the dataset for them (they use numpy arrays in their model)\n",
        "\n",
        "\n",
        "X_valid, y_valid = [], []\n",
        "for data, labels in valid_loader:\n",
        "    X_valid.append(data.numpy())\n",
        "    y_valid.append(labels.numpy())\n",
        "X_valid = np.concatenate(X_valid)\n",
        "y_valid = np.concatenate(y_valid)\n",
        "\n",
        "X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
        "\n",
        "\n",
        "X_train, y_train = [], []\n",
        "for data, labels in train_loader:\n",
        "    X_train.append(data.numpy())\n",
        "    y_train.append(labels.numpy())\n",
        "X_train = np.concatenate(X_train)\n",
        "y_train = np.concatenate(y_train)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxIA7jzZBIjP"
      },
      "source": [
        "# Now we build the CNN and the optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmqQPUHMUjzP"
      },
      "source": [
        "We will try different deep convolutional model to train with the CIFAR10 dataset :\n",
        "WideResNet, Resnet, AlexNet \n",
        "(cuda shifts the process on the GPU)\n",
        "You can also choose to work with a Random Forest or a SVC \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1jmoAxYUXYm"
      },
      "outputs": [],
      "source": [
        "#Launch this cell to work with WideResNet as the network\n",
        "\n",
        "net = WideResNet(28, 2, dropout_rate=0.0, num_classes=num_class)\n",
        "net =net.cuda()\n",
        "net_save = WideResNet(28, 2, dropout_rate=0.0, num_classes=num_class) # model where to save the results\n",
        "net_save =net_save.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U3HwxPPIUXqd"
      },
      "outputs": [],
      "source": [
        "#Launch this cell to work with resnet18 as the network\n",
        "#By adding the parameter weights=\"IMAGENET1K_V1\" we use the pretrained weights, if we don't put anything for the parameter it starts from random weights\n",
        "weights=\"IMAGENET1K_V1\"\n",
        "# weights=None\n",
        "\n",
        "net = models.resnet18(weights=weights)\n",
        "net.fc = nn.Linear(512, num_classes)\n",
        "net = net.cuda()\n",
        "net_save = models.resnet18(weights=weights)\n",
        "net_save.fc = nn.Linear(512, num_classes)\n",
        "net_save =net_save.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uciwU-aZUXwN"
      },
      "outputs": [],
      "source": [
        "#Launch this cell to work with alexnet as the network\n",
        "#By adding the parameter weights=\"IMAGENET1K_V1\" we use the pretrained weights, if you want to use random weight change the weights variable to None\n",
        "\n",
        "weights=\"IMAGENET1K_V1\"\n",
        "# weights=None\n",
        "\n",
        "\n",
        "net = models.alexnet(weights=weights)\n",
        "net.classifier[6] = nn.Linear(4096,num_classes)\n",
        "net = net.cuda()\n",
        "\n",
        "net_save = models.alexnet(weights=weights)\n",
        "net_save.classifier[6] = nn.Linear(4096,num_classes)\n",
        "net_save =net_save.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klXIYCo-VLKM"
      },
      "outputs": [],
      "source": [
        "#Launch this cell to work with a Random Forest as the network\n",
        "#You can modify the number of trees in the forest by changing the n_estimators parameter \n",
        "clf = RandomForestClassifier(n_estimators=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ferjcxn7VR6y"
      },
      "outputs": [],
      "source": [
        "#Launch this cell to work with a SVC model as the network\n",
        "clf = svm.SVC()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY_jn6VVBTgk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HSobiPQBNjh"
      },
      "outputs": [],
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "def learning_rate_scheduler(init, epoch):\n",
        "    optim_factor = 0\n",
        "    if(epoch > 200):\n",
        "        optim_factor = 3\n",
        "    elif(epoch > 160):\n",
        "        optim_factor = 2\n",
        "    elif(epoch > 80):\n",
        "        optim_factor = 1\n",
        "\n",
        "    return init*math.pow(0.1, optim_factor)\n",
        "\n",
        "\n",
        "# Training \n",
        "def train(epoch,net,trainloader,log_interval=15):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate_scheduler(lr, epoch)))\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate_scheduler(lr, epoch), momentum=0.9, weight_decay=5e-4)\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        " \n",
        "        inputs, targets = inputs.cuda(), targets.cuda() # GPU settings\n",
        "        optimizer.zero_grad()\n",
        "        #inputs, targets = Variable(inputs), Variable(targets)\n",
        "        outputs = net(inputs)               # Forward Propagation\n",
        "        loss = criterion(outputs, targets)  # Loss\n",
        "        loss.backward()  # Backward Propagation\n",
        "        optimizer.step() # Optimizer update\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, num_epochs, batch_idx+1,\n",
        "                    (len(trainloader.dataset)//batch_size)+1, loss.item(), 100.*correct/total))\n",
        "\n",
        "\n",
        "def test(epoch,net,testloader):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            \n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        \n",
        "    acc = 100.*correct/total\n",
        "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpnbckfWBWbB"
      },
      "outputs": [],
      "source": [
        "#Training for the CNN models\n",
        "\n",
        "best_acc=0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train(epoch,net,train_loader)\n",
        "    acc = test(epoch,net,valid_loader)\n",
        "    # Save checkpoint when best model\n",
        "    if acc > best_acc:\n",
        "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "        net_save.load_state_dict(net.state_dict(), strict=True)\n",
        "        best_acc=acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtY7lIayMzN0"
      },
      "outputs": [],
      "source": [
        "#Training for the SVM or Random Forest\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weX9mgbZBiNO"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDqFxbtmBkAL"
      },
      "outputs": [],
      "source": [
        "#Evaluation for the CNN models \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def test_final(net,testloader):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            \n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "            if batch_idx == 0:\n",
        "                predicted_concat = predicted.clone()\n",
        "            else:\n",
        "                predicted_concat = torch.cat((predicted_concat, predicted), 0)\n",
        "\n",
        "        # Save checkpoint when best model\n",
        "    acc = 100.*correct/total\n",
        "    print(\"\\n| TEST \\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %( loss.item(), acc))\n",
        "    return predicted_concat.cpu().numpy()\n",
        "    \n",
        "\n",
        "predicted_concat = test_final(net,test_loader)\n",
        "\n",
        "\n",
        "id_concat =range(len(predicted_concat))\n",
        "my_submission = pd.DataFrame({'Id': id_concat,'Expected': predicted_concat})\n",
        "\n",
        "# you could use any filename. We choose submission here\n",
        "my_submission.to_csv('submission2.csv', index=False)\n",
        "print('we have saved the submission !! ')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofmhJGIRnLzt",
        "outputId": "dbcb4d3b-b4cc-4703-82e2-312977aeb364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.334\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test data for the Random Forest or the SVM \n",
        "y_pred = clf.predict(X_valid)\n",
        "\n",
        "# Calculate accuracy\n",
        "acc = accuracy_score(y_valid, y_pred)\n",
        "print(\"Accuracy:\", acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij_IBcJMd5mz"
      },
      "source": [
        "#FixMatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "296d57a02f64422199127545f51a0005",
            "c6ff247ea50f44698cd7183c5179c13b",
            "a1b5d168fc0f48b692edee9f7a1905ad",
            "d3da2f563f3c4cb7adb98defb0711ff2",
            "320390e62cca4430a80d6b63b2d94c77",
            "51dbfe1ea8e04ea8a23e4793dacade09",
            "c6870e7708394c1881033ea2621891b0",
            "a8874eb4b562405a9c1b0e088add8a94",
            "46ef80ec3df84215837983a98a1ebdc5",
            "dbb6bef857fe4d1aa920f0af5e34a915",
            "e52787d63a6b4d689e577ad080e8b323"
          ]
        },
        "id": "u44CLkvnd7M9",
        "outputId": "7677bd96-ab48-4d6d-e442-6ca3fbee36d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "296d57a02f64422199127545f51a0005",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n",
            "Files already downloaded and verified\n",
            "Generating permutations...\n",
            "Extracting datasets...\n",
            "Creating dataloaders...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "n_classes = 10\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "train_class_size = 100\n",
        "valid_class_size = 200\n",
        "unlabeled_ratio = 7\n",
        "confidence_threshold = 0.6\n",
        "\n",
        "#set sizes\n",
        "valid_size = n_classes * valid_class_size\n",
        "labeled_size = n_classes * train_class_size\n",
        "unlabeled_size = labeled_size * unlabeled_ratio\n",
        "\n",
        "#load datasets\n",
        "print(\"Loading datasets...\")\n",
        "train_ds = torchvision.datasets.CIFAR10(root=\"./cifar10\", train=True,  download=True)\n",
        "valid_ds = torchvision.datasets.CIFAR10(root=\"./cifar10\", train=False, download=True)\n",
        "\n",
        "\n",
        "#select random data\n",
        "print(\"Generating permutations...\")\n",
        "rng = np.random.default_rng()\n",
        "valid_ids     = rng.permutation(valid_ds.data.shape[0])[:valid_size].astype(int)\n",
        "labeled_ids   = rng.permutation(train_ds.data.shape[0])[:labeled_size].astype(int)\n",
        "unlabeled_ids = rng.permutation(train_ds.data.shape[0])[:unlabeled_size].astype(int)\n",
        "\n",
        "#extract validation and training sets from datasets\n",
        "print(\"Extracting datasets...\")\n",
        "x_valid = np.array(valid_ds.data)[valid_ids]\n",
        "y_valid = np.array(valid_ds.targets)[valid_ids]\n",
        "x_labeled = np.array(train_ds.data)[labeled_ids]\n",
        "y_labeled = np.array(train_ds.targets)[labeled_ids]\n",
        "x_unlabeled = np.array(train_ds.data)[unlabeled_ids]\n",
        "\n",
        "#creating dataloaders\n",
        "print(\"Creating dataloaders...\")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(Original_test_data_x, Original_test_data_y, transform=transform_test),\n",
        "    batch_size = batch_size,shuffle=False, num_workers=2)\n",
        "labeled_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_labeled, y_labeled, transform=transform_train),\n",
        "    batch_size=batch_size,shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT89Go-5qI-R"
      },
      "outputs": [],
      "source": [
        "# Training \n",
        "def training_epoch(epoch,net,loader,log_interval=15):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate_scheduler(lr, epoch)))\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate_scheduler(lr, epoch), momentum=0.9, weight_decay=5e-4)\n",
        "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, num_epochs, batch_idx+1,\n",
        "                    (len(trainloader.dataset)//batch_size)+1, loss.item(), 100.*correct/total))\n",
        "\n",
        "\n",
        "def test(epoch,net,testloader):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            \n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        \n",
        "    acc = 100.*correct/total\n",
        "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n",
        "    return acc\n",
        "\n",
        "def learning_rate_scheduler(init, epoch):\n",
        "    optim_factor = 0\n",
        "    if(epoch > 200):\n",
        "        optim_factor = 3\n",
        "    elif(epoch > 160):\n",
        "        optim_factor = 2\n",
        "    elif(epoch > 80):\n",
        "        optim_factor = 1\n",
        "    return init*math.pow(0.1, optim_factor)\n",
        "\n",
        "def pseudo_label(net, unlabeled, threshold=0.5):\n",
        "  n = unlabeled.size(0)\n",
        "  labels = np.zeros(n)\n",
        "  label_count = 0\n",
        "  predictions = net(unlabeled)\n",
        "  for i in range(n):\n",
        "    probs = torch.functional.softmax(predictions[i])\n",
        "    confidence = torch.max(prob)\n",
        "    if confidence > threshold:\n",
        "      labels[i] = [1 if p == confidence else 0 for p in prob]\n",
        "  return labels\n",
        "\n",
        "\n",
        "def pseudolabeled_loader(unlabeled, labels):\n",
        "  count = torch.count_nonzero(labels)\n",
        "  xy_index = 0\n",
        "  nonzeros = torch.nonzero(torch.sum(labels,dim=2))\n",
        "  n = nonzeros.size(0)\n",
        "  x = torch.zeros((n,*unlabeled[0].size))\n",
        "  y = torch.zeros((n,n_classes))\n",
        "  for i in nonzeros:\n",
        "    x[xy_index] = unlabeled[i]\n",
        "    y[xy_index] = labels[i]\n",
        "  return torch.utils.data.DataLoader(Dataset_sub_CIFAR(x, y), batch_size = batch_size,shuffle=False, num_workers=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Ho830Yx6fK0_",
        "outputId": "c9763f09-3386-455e-cde2-62dda18f02be"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-16149cb1f035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWideResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnet_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWideResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model where to save the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnet_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "net = WideResNet(28, 2, dropout_rate=0.0, num_classes=num_class)\n",
        "net = net.cuda()\n",
        "net_save = WideResNet(28, 2, dropout_rate=0.0, num_classes=num_class) # model where to save the results\n",
        "net_save = net_save.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "weak_augment = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.Resize(32),\n",
        "    transforms.RandomCrop(size=32,padding=int(32*0.125),padding_mode='reflect')\n",
        "])\n",
        "\n",
        "def strong_augment(n_augments=2,magnitude=0.5):\n",
        "  return transforms.Compose([\n",
        "      transforms.RandomErasing(p=1,ratio=(1,1),scale=(0.1,0.1),value=127),\n",
        "      transforms.RandAugment(n_augments,magnitude) ])\n",
        "\n",
        "#Labeled training\n",
        "net.train()\n",
        "for epoch in range(epochs):\n",
        "  training_epoch(epoch, net, labeled_loader)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  weak_augments = weak_augment(x_unlabeled)\n",
        "  pseudolabels = pseudo_label(net, weak_augments, 0.6)\n",
        "  strong_augments = strong_augment()(x_unlabeled)\n",
        "  loader = pseudolabeled_loader(strong_augments, pseudolabels)\n",
        "  training_epoch(epoch, net, pseudolabeled_loader)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrJS4AqABprt"
      },
      "source": [
        "# Question for the report\n",
        "I want that you send me a small report with the answer to this question and your notebook.\n",
        "- Q0: Please train wideresnet, and please understand a bit wideresnet.\n",
        "- Q1: Please change DNN with a Resnet 18. Try with one that is pre-trained and one that is not pre-trained. \n",
        "- Q2: Please change DNN with an AlexNet. Try with one that is pre-trained and one that is not pre-trained. (Be careful, you need a bit to play with the learning rate, for questions two, one and zeros I want to see the training loss and training accuracy. What other curb is interesting? Plot it and analyse it.)\n",
        "- Q3: Please try to train an SVM and a random forest.\n",
        "- Q4 After you have trained several models please draw a table and make some conclusions.\n",
        "-  Q5 Read the paper fixmatch (https://amitness.com/2020/03/fixmatch-semi-supervised/) and explain it.\n",
        "- Q6 please try to implement it and try to make it work.\n",
        "- Q7 What can we do to avoid overfitting in Deep learning?\n",
        "\n",
        "\n",
        "*Q0-Q5 = 14 pts*\n",
        "\n",
        "*Q6 = 6 pts*\n",
        "\n",
        "*Q7 = 1 pts*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jxIA7jzZBIjP",
        "tY_jn6VVBTgk",
        "weX9mgbZBiNO"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a9ed2f9b7064e83bc416e4409c30b74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7987c8cf08428a98d2408c7732efa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2238772441414765a6c0d6b86337ef75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed0ca27c2a9342969d84fa318c4593eb",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_302527af463746388f2d6f004df6fe44",
            "value": 2916352
          }
        },
        "25467d38472b4631b0799f17dc4f0746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29376e5f1ace4d94ad9f5309c635a1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "296d57a02f64422199127545f51a0005": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6ff247ea50f44698cd7183c5179c13b",
              "IPY_MODEL_a1b5d168fc0f48b692edee9f7a1905ad",
              "IPY_MODEL_d3da2f563f3c4cb7adb98defb0711ff2"
            ],
            "layout": "IPY_MODEL_320390e62cca4430a80d6b63b2d94c77"
          }
        },
        "302527af463746388f2d6f004df6fe44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "320390e62cca4430a80d6b63b2d94c77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ef80ec3df84215837983a98a1ebdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51dbfe1ea8e04ea8a23e4793dacade09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9950e6ede6c94882abdc259ef6e7e3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a9ed2f9b7064e83bc416e4409c30b74",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_29376e5f1ace4d94ad9f5309c635a1e4",
            "value": "  2%"
          }
        },
        "a1b5d168fc0f48b692edee9f7a1905ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8874eb4b562405a9c1b0e088add8a94",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46ef80ec3df84215837983a98a1ebdc5",
            "value": 170498071
          }
        },
        "a8874eb4b562405a9c1b0e088add8a94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b754bf3d704c8ca49f3d94ffd0cb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9950e6ede6c94882abdc259ef6e7e3fc",
              "IPY_MODEL_2238772441414765a6c0d6b86337ef75",
              "IPY_MODEL_e78b47908dae4bf9987f1d09cf94a089"
            ],
            "layout": "IPY_MODEL_0e7987c8cf08428a98d2408c7732efa4"
          }
        },
        "c6870e7708394c1881033ea2621891b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6ff247ea50f44698cd7183c5179c13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51dbfe1ea8e04ea8a23e4793dacade09",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c6870e7708394c1881033ea2621891b0",
            "value": "100%"
          }
        },
        "d3da2f563f3c4cb7adb98defb0711ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb6bef857fe4d1aa920f0af5e34a915",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e52787d63a6b4d689e577ad080e8b323",
            "value": " 170498071/170498071 [00:01&lt;00:00, 110336720.99it/s]"
          }
        },
        "dbb6bef857fe4d1aa920f0af5e34a915": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e52787d63a6b4d689e577ad080e8b323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e78b47908dae4bf9987f1d09cf94a089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef0a5ac2261349a58ea5a8ba73c2639a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_25467d38472b4631b0799f17dc4f0746",
            "value": " 2916352/170498071 [00:06&lt;06:16, 445481.36it/s]"
          }
        },
        "ed0ca27c2a9342969d84fa318c4593eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef0a5ac2261349a58ea5a8ba73c2639a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}